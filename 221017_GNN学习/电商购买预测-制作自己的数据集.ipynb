{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d266468d-3f54-4242-8efa-a1a3b13f5fb5",
   "metadata": {},
   "source": [
    "## 创建torch_geometric中的图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "512f3a22-71d9-438c-8de7-476f2d1f2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c5d9da-f06d-455e-8900-53fa0a416c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4, 2], edge_index=[2, 5], y=[4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[2,1], [5,6],[3,7],[12,0]], dtype=torch.float)\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.float)\n",
    "edge_index = torch.tensor([[0, 1, 2, 0, 3],\n",
    "                           [1, 0, 1, 3, 2]], dtype=torch.long)\n",
    "# 边的顺序无所谓\n",
    "\n",
    "data = Data(x=x, y=y, edge_index=edge_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add9cd3-6129-4ca3-ae33-152074aa0977",
   "metadata": {},
   "source": [
    "## 电商转化率预测\n",
    "+ yoochoose-clicks: 用户的浏览行为，其中一个session_id就表示一次登录都浏览了啥东西\n",
    "+ item_id就是他所浏览的商品，其中yoochoose-buys描述了他最终是否购买，也就是标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b0bb1fa-541b-4a67-a682-e0e7b9b6bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac5ec29-e40b-411f-8a29-5e45a37403eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MyDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=True, pre_transform=None):\n",
    "        super(MyDataset, self).__init__(root, transform, pre_transform) # transform就是数据增强，对每一个数据都执行\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "    \n",
    "    # 检查self.raw_dir目录下是否存在raw_file_names()属性方法返回的每个文件\n",
    "    # 如果文件不存在，则调用download()方法执行原始文件下载\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    \n",
    "    # 检查self.processed_dir目录下是否存在self.processed_file_names属性方法返回的所有文件，没有就会走process\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['MyDataset.dataset']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        # 自己定义数据处理方法，处理为torch_geometric可用的Data类型\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9317b44-abf9-4653-92cc-34a85fda71f0",
   "metadata": {},
   "source": [
    "## 构建网络模型\n",
    "+ 与CNN的卷积核池化类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01e2da8c-8216-4a39-ad51-0f6973905886",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "from torch_geometric.nn import TopKPooling, SAGEConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch.nn.functional as F\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = SAGEConv(embed_dim, 128)\n",
    "        self.pool1 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv2 = SAGEConv(128, 128)\n",
    "        self.pool2 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv3 = SAGEConv(128, 128)\n",
    "        self.pool3 = TopKPooling(128, ratio=0.8)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=df.item_id.max() + 10, embedding_dim=embed_dim)\n",
    "        self.lin1 = torch.nn.Linear(128, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 64)\n",
    "        self.lin3 = torch.nn.Linear(64, 1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(128)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.act2 = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # x： n * 1, 其中每个图中点的个数是不同的\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        x = self.item_embedding(x)\n",
    "        x = x.squeeze(1) # n*128\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edeg_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch) # pool 之后得到 n*128个点\n",
    "        x1 = gap(x, batch)\n",
    "        x = F.relu(self.conv2(x, edeg_index))\n",
    "        x, edeg_index, _, batch, _, _ = self.pool2(x, edeg_index, None, batch)\n",
    "        x2 = gap(x, batch)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x, edeg_index, _, batch, _, _ = self.pool3(x, edeg_index, None, batch)\n",
    "        x3 = gap(x, batch)\n",
    "        x = x1 + x2 + x3 # 获取不同尺度的全局特征\n",
    "        \n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        \n",
    "        x = torch.sigmoid(self.lin3(x).squeeze(1)) # batch个结果\n",
    "        \n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69307c33-7876-49fd-819b-ca338be4970b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9316\\862903082.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss_all\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mcrit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9316\\1578291170.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSAGEConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTopKPooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data\n",
    "        opt.zero_grad()\n",
    "        output = model(data)\n",
    "        label = data.y\n",
    "        loss = crit(output, label)\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        opt.step()\n",
    "    return loss_all / len(dataset)\n",
    "\n",
    "model = Net()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "crit = torch.nn.BCELoss()\n",
    "train_laader = DataLoader(dataset, batch_size=64)\n",
    "for epoch in range(10):\n",
    "    print(\"epoch:\", epoch)\n",
    "    loss = train()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d01723-1246-469b-bcbb-4e56fbdbe7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "torchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
