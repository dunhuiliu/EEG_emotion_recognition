{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8a2f88-794f-41ec-8149-bc8a5e11166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import add_self_loops, degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d86c9a-a9b3-496d-a650-e4b4c054fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def data_split(train_ratio=0.7):\n",
    "#     load_dir = '../global_data/time_76800x32x128/'\n",
    "\n",
    "#     trials = np.load(load_dir + 'trials.npy')\n",
    "#     bases = np.load(load_dir + 'bases.npy')\n",
    "#     labels = np.load(load_dir + 'labels.npy')\n",
    "#     # print(trials.shape, bases.shape, labels.shape)\n",
    "    \n",
    "#     # 去基线\n",
    "#     for i, base in enumerate(bases):\n",
    "#         trials[i * 60 : (i + 1) * 60] -= base\n",
    "    \n",
    "#     # 离散化标签\n",
    "#     labels = np.where(labels >= 5, 1, 0)\n",
    "\n",
    "#     # 复制标签以对齐样本\n",
    "#     labels = np.repeat(labels, 60, axis = 0)\n",
    "#     # print(labels.shape)\n",
    "    \n",
    "#     shuffle_list = np.arange(trials.shape[0])\n",
    "#     np.random.shuffle(shuffle_list)\n",
    "#     trials = trials[shuffle_list]\n",
    "#     labels = labels[shuffle_list]\n",
    "    \n",
    "#     cut_point = int(trials.shape[0] * train_ratio)\n",
    "#     train_features, train_labels = trials[:cut_point], labels[:cut_point]\n",
    "#     test_features, test_labels = trials[cut_point:], labels[cut_point:]\n",
    "    \n",
    "#     train_features = train_features.reshape((cut_point, 32 * 128))\n",
    "#     test_features = test_features.reshape((trials.shape[0] - cut_point, 32 * 128))\n",
    "    \n",
    "#     mean = train_features.mean(axis = 0)\n",
    "#     std = train_features.std(axis = 0)\n",
    "    \n",
    "#     train_features = (train_features - mean) / std\n",
    "#     test_features = (test_features - mean) / std\n",
    "    \n",
    "#     train_features = train_features.reshape((cut_point, 32, 128))\n",
    "#     test_features = test_features.reshape((trials.shape[0] - cut_point, 32, 128))\n",
    "    \n",
    "#     save_dir = 'data/data_split/'\n",
    "#     np.save(save_dir + 'train_features.npy', train_features)\n",
    "#     np.save(save_dir + 'train_labels.npy', train_labels)\n",
    "#     np.save(save_dir + 'test_features.npy', test_features)\n",
    "#     np.save(save_dir + 'test_labels.npy', test_labels)\n",
    "\n",
    "# data_split(train_ratio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb3182e-f053-4458-b057-bfd300617f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(is_train_data=True):\n",
    "    save_dir = 'data/data_split/'\n",
    "    if is_train_data:\n",
    "        features = np.load(save_dir + 'train_features.npy')\n",
    "        labels = np.load(save_dir + 'train_labels.npy')\n",
    "    else:\n",
    "        features = np.load(save_dir + 'test_features.npy')\n",
    "        labels = np.load(save_dir + 'test_labels.npy')\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b5e808-1250-4784-b6b7-a0e58d86017a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_edge_index(self_loop_only=False):\n",
    "    edge_index = [[],[]]\n",
    "    weight = []\n",
    "    \n",
    "    if self_loop_only:\n",
    "        edge_index = torch.tensor(np.array(edge_index), dtype=torch.long)\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=32)\n",
    "        return edge_index\n",
    "    \n",
    "    adjacency_edge = {\n",
    "        1:[2],\n",
    "        2:[3, 19],\n",
    "        3:[5, 6],\n",
    "        4:[5],\n",
    "        5:[8, 7],\n",
    "        6:[7, 24],\n",
    "        7:[9, 10],\n",
    "        8:[9],\n",
    "        9:[12, 11],\n",
    "        10:[11, 16],\n",
    "        11:[13],\n",
    "        12:[],\n",
    "        13:[14, 15],\n",
    "        14:[15],\n",
    "        15:[],\n",
    "        16:[13, 31],\n",
    "        17:[18],\n",
    "        18:[19, 20],\n",
    "        19:[6, 23],\n",
    "        20:[23, 22],\n",
    "        21:[22],\n",
    "        22:[25, 26],\n",
    "        23:[24, 25],\n",
    "        24:[10, 28],\n",
    "        25:[28, 27],\n",
    "        26:[27],\n",
    "        27:[29, 30],\n",
    "        28:[16, 29],\n",
    "        29:[31],\n",
    "        30:[],\n",
    "        31:[15, 32],\n",
    "        32:[15]\n",
    "    }\n",
    "    \n",
    "    for start, end_list in adjacency_edge.items():\n",
    "        if len(end_list) == 0:\n",
    "            continue\n",
    "        for end in end_list:\n",
    "            edge_index[0].append(start - 1)\n",
    "            edge_index[1].append(end - 1)\n",
    "            edge_index[0].append(end - 1)\n",
    "            edge_index[1].append(start - 1)\n",
    "           \n",
    "    edge_index = torch.tensor(np.array(edge_index), dtype=torch.long)\n",
    "    \n",
    "    edge_index, _ = add_self_loops(edge_index, num_nodes=32)\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fcb8368-b508-41fb-baa4-5e35d16ff337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index = [[],[]]\n",
    "# weight = []\n",
    "\n",
    "# #用一个字典保存 通道下标对应 9 * 9 矩阵的下标\n",
    "# chan_to_1020={0:[0,3],1:[1,3],2:[2,2],3:[2,0],4:[3,1],5:[3,3],6:[4,2],7:[4,0],8:[5,1],\n",
    "#               9:[5,3],10:[6,2],11:[6,0],12:[7,3],13:[8,3],14:[8,4],15:[6,4],16:[0,5],\n",
    "#               17:[1,5],18:[2,4],19:[2,6],20:[2,8],21:[3,7],22:[3,5],23:[4,4],24:[4,6],\n",
    "#                 25:[4,8],26:[5,7],27:[5,5],28:[6,6],29:[6,8],30:[7,5],31:[8,5]}\n",
    "# maps = np.zeros(shape=(9, 9), dtype=int)\n",
    "\n",
    "# for k, v in chan_to_1020.items():\n",
    "#     maps[v[0]][v[1]] = k + 1\n",
    "# print(maps)\n",
    "# plt.matshow(maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d5064c8-5b77-4c0a-8056-45b125c07195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data, Dataset\n",
    "\n",
    "class MyDataset(InMemoryDataset):\n",
    "    is_train_data = None\n",
    "    edge_index = None\n",
    "    def __init__(self, root, is_train_data, edge_index):\n",
    "        self.is_train_data = is_train_data\n",
    "        self.edge_index = edge_index\n",
    "        super(MyDataset, self).__init__(root)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    \n",
    "    # 检查self.processed_dir目录下是否存在self.processed_file_names属性方法返回的所有文件，没有就会走process\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        if self.is_train_data:\n",
    "            return ['train.dataset']\n",
    "        return ['test.datset']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        features, labels = None, None\n",
    "        \n",
    "        if self.is_train_data:\n",
    "            features, labels = load_data(is_train_data=True)\n",
    "        else:\n",
    "            features, labels = load_data(is_train_data=False)\n",
    "            \n",
    "        data_list = []\n",
    "        for i in range(features.shape[0]):\n",
    "            x = torch.tensor(features[i], dtype=torch.float)\n",
    "            y = torch.tensor([labels[i]], dtype=torch.long)\n",
    "            data = Data(x = x, edge_index=self.edge_index, y=y)\n",
    "            data_list.append(data)\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        \n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379387d3-85fb-4d21-80cc-4541f55a331f",
   "metadata": {},
   "source": [
    "+ data.x: Node feature matrix with shape [num_nodes, num_node_features]\n",
    "\n",
    "+ data.edge_index: Graph connectivity in COO format with shape [2, num_edges] and type torch.long\n",
    "\n",
    "+ data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n",
    "\n",
    "+ data.y: Target to train against (may have arbitrary shape), e.g., node-level targets of shape [num_nodes, *] or graph-level targets of shape [1, *]\n",
    "\n",
    "+ data.pos: Node position matrix with shape [num_nodes, num_dimensions]\n",
    "\n",
    "--- \n",
    "\n",
    "- train_mask denotes against which nodes to train (140 nodes),\n",
    "\n",
    "- val_mask denotes which nodes to use for validation, e.g., to perform early stopping (500 nodes),\n",
    "\n",
    "- test_mask denotes against which nodes to test (1000 nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f15c9eec-1f00-4be2-9e8e-11ca12edadee",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_loop_only = False\n",
    "edge_index = get_edge_index(self_loop_only=self_loop_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f54215ce-14bd-4072-bbd2-c16971a9f9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "trainData = MyDataset(root='data/data_split', is_train_data=True, edge_index=edge_index)\n",
    "trainDataLoader = DataLoader(trainData, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testData = MyDataset(root='data/data_split', is_train_data=False, edge_index=edge_index)\n",
    "testDataLoader = DataLoader(testData, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f0803e6-269e-4f79-832b-315ec6ea89cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import TopKPooling, SAGEConv, GCNConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "embed_dim = 128\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(embed_dim, 256) # SAGEConv\n",
    "        self.pool1 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv2 = GCNConv(256, 256)\n",
    "        self.pool2 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv3 = GCNConv(1280, 1280)\n",
    "        self.pool3 = TopKPooling(16, ratio=0.8)\n",
    "        # self.item_embedding = torch.nn.Embedding(num_embeddings=df.item_id.max() + 10, embedding_dim=embed_dim)\n",
    "        self.lin1 = torch.nn.Linear(8192, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 128)\n",
    "        self.lin3 = torch.nn.Linear(128, 2)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(1280)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(640)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # x： n * 1, 其中每个图中点的个数是不同的\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # x = self.item_embedding(x)\n",
    "        # x = x.squeeze(1) # n*128\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        # x, edeg_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch) # pool 之后得到 n*128个点\n",
    "        # x1 = gap(x, batch)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        # x, edeg_index, _, batch, _, _ = self.pool2(x, edeg_index, None, batch)\n",
    "        # x2 = gap(x, batch)\n",
    "        # x = F.relu(self.conv3(x, edge_index))\n",
    "        # x, edeg_index, _, batch, _, _ = self.pool3(x, edeg_index, None, batch)\n",
    "        # x3 = gap(x, batch)\n",
    "        # x = x1 + x2 + x3 # 获取不同尺度的全局特征\n",
    "        \n",
    "        batch_size = data.y.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "#         x = torch.mean(x, dim=1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "#         x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50636f52-fc65-4f4a-94e1-2e79dd89b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(emo_dim):\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch_id, batch in enumerate(trainDataLoader):\n",
    "        batch.to(device)\n",
    "        opt.zero_grad()\n",
    "        output = model(batch)\n",
    "        loss = crit(output, batch.y[:, emo_dim])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        output = torch.max(output, 1)[1]\n",
    "        train_acc += (output == batch.y[:, emo_dim]).sum()\n",
    "    \n",
    "    num_train_sample = len(trainDataLoader.dataset)\n",
    "    train_loss = train_loss / num_train_sample\n",
    "    train_acc = train_acc / num_train_sample\n",
    "    \n",
    "    # check测试集的性能\n",
    "    vali_loss = 0\n",
    "    vali_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for batch in testDataLoader:\n",
    "        batch.to(device)\n",
    "        output = model(batch)\n",
    "        loss = crit(output, batch.y[:, emo_dim])\n",
    "        vali_loss += loss.item()\n",
    "        output = torch.max(output, 1)[1]\n",
    "        vali_acc += (output == batch.y[:, emo_dim]).sum()\n",
    "    \n",
    "    num_test_sample = len(testDataLoader.dataset)\n",
    "    vali_loss = vali_loss / num_test_sample\n",
    "    vali_acc = vali_acc / num_test_sample\n",
    "    \n",
    "    print(f'train_loss:{train_loss:.6f}, train_acc:{train_acc:.6f}, test_loss:{vali_loss:.6f}, test_acc:{vali_acc:.6f}')\n",
    "    \n",
    "    return train_loss, train_acc, vali_loss, vali_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef3f3d55-fc83-475e-a697-9b8a12789830",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "model = Net().to(device)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "crit = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "emo_dim = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f5d67c7-8ea4-4e5d-aff1-4f2b832d6101",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->epoch:1, train_loss:0.018506, train_acc:0.672193, test_loss:0.015058, test_acc:0.768880\n",
      "->epoch:2, train_loss:0.011829, train_acc:0.825926, test_loss:0.011200, test_acc:0.831250\n",
      "->epoch:3, train_loss:0.008477, train_acc:0.882378, test_loss:0.011049, test_acc:0.849740\n",
      "->epoch:4, train_loss:0.006399, train_acc:0.912876, test_loss:0.009783, test_acc:0.865495\n",
      "->epoch:5, train_loss:0.005030, train_acc:0.931800, test_loss:0.010573, test_acc:0.868229\n",
      "->epoch:6, train_loss:0.004244, train_acc:0.943461, test_loss:0.010195, test_acc:0.872656\n",
      "->epoch:7, train_loss:0.003623, train_acc:0.953024, test_loss:0.011128, test_acc:0.879948\n",
      "->epoch:8, train_loss:0.003076, train_acc:0.959997, test_loss:0.010539, test_acc:0.874740\n",
      "->epoch:9, train_loss:0.002742, train_acc:0.965422, test_loss:0.012460, test_acc:0.879818\n",
      "->epoch:10, train_loss:0.002418, train_acc:0.969155, test_loss:0.012943, test_acc:0.885026\n",
      "->epoch:11, train_loss:0.002237, train_acc:0.972208, test_loss:0.011114, test_acc:0.889323\n",
      "->epoch:12, train_loss:0.001992, train_acc:0.975868, test_loss:0.012725, test_acc:0.884375\n",
      "->epoch:13, train_loss:0.001832, train_acc:0.978313, test_loss:0.013668, test_acc:0.881771\n",
      "->epoch:14, train_loss:0.001702, train_acc:0.979152, test_loss:0.013517, test_acc:0.887630\n",
      "->epoch:15, train_loss:0.001554, train_acc:0.982350, test_loss:0.014735, test_acc:0.891406\n",
      "->epoch:16, train_loss:0.001478, train_acc:0.983015, test_loss:0.014073, test_acc:0.884375\n",
      "->epoch:17, train_loss:0.001455, train_acc:0.982914, test_loss:0.015276, test_acc:0.888542\n",
      "->epoch:18, train_loss:0.001295, train_acc:0.985851, test_loss:0.014355, test_acc:0.889453\n",
      "->epoch:19, train_loss:0.001258, train_acc:0.986487, test_loss:0.014154, test_acc:0.890625\n",
      "->epoch:20, train_loss:0.001169, train_acc:0.987529, test_loss:0.014670, test_acc:0.890365\n",
      "->epoch:21, train_loss:0.001178, train_acc:0.987645, test_loss:0.016914, test_acc:0.890885\n",
      "->epoch:22, train_loss:0.001134, train_acc:0.988542, test_loss:0.015277, test_acc:0.889974\n",
      "->epoch:23, train_loss:0.001109, train_acc:0.988527, test_loss:0.014808, test_acc:0.887240\n",
      "->epoch:24, train_loss:0.000876, train_acc:0.990162, test_loss:0.018119, test_acc:0.894401\n",
      "->epoch:25, train_loss:0.000993, train_acc:0.989699, test_loss:0.016555, test_acc:0.893620\n",
      "->epoch:26, train_loss:0.000855, train_acc:0.991001, test_loss:0.016538, test_acc:0.890365\n",
      "->epoch:27, train_loss:0.000968, train_acc:0.989800, test_loss:0.019200, test_acc:0.890625\n",
      "->epoch:28, train_loss:0.000776, train_acc:0.991884, test_loss:0.019911, test_acc:0.889453\n",
      "->epoch:29, train_loss:0.000867, train_acc:0.990726, test_loss:0.017740, test_acc:0.891016\n",
      "->epoch:30, train_loss:0.000786, train_acc:0.991826, test_loss:0.019741, test_acc:0.893099\n",
      "->epoch:31, train_loss:0.000809, train_acc:0.991609, test_loss:0.020747, test_acc:0.888412\n",
      "->epoch:32, train_loss:0.000819, train_acc:0.992173, test_loss:0.020655, test_acc:0.895313\n",
      "->epoch:33, train_loss:0.000853, train_acc:0.991508, test_loss:0.020153, test_acc:0.892708\n",
      "->epoch:34, train_loss:0.000760, train_acc:0.992376, test_loss:0.021170, test_acc:0.889453\n",
      "->epoch:35, train_loss:0.000680, train_acc:0.992708, test_loss:0.018332, test_acc:0.893359\n",
      "->epoch:36, "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28556\\1410925.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'->epoch:{epoch + 1}'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memo_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#     print(f'->epoch:{epoch:3d}, train_loss={train_loss:.6f}, train_acc={train_acc:.4f}, val_loss={val_loss:.6f}, val_acc={val_acc:.4f}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28556\\974053572.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(emo_dim)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memo_dim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\torchgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28556\\2864623968.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# x = self.item_embedding(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# x = x.squeeze(1) # n*128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;31m# x, edeg_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch) # pool 之后得到 n*128个点\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# x1 = gap(x, batch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\torchgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\torchgpu\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    176\u001b[0m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0;32m    177\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n\u001b[0m\u001b[0;32m    179\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcached\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\torchgpu\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_self_loops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             edge_index, tmp_edge_weight = add_remaining_self_loops(\n\u001b[1;32m---> 62\u001b[1;33m                 edge_index, edge_weight, fill_value, num_nodes)\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mtmp_edge_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0medge_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_edge_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\torchgpu\\lib\\site-packages\\torch_geometric\\utils\\loop.py\u001b[0m in \u001b[0;36madd_remaining_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[0minv_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m         \u001b[0mloop_attr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minv_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minv_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[0medge_attr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_attr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    print(f'->epoch:{epoch + 1}', end = ', ')\n",
    "    train_loss, train_acc, val_loss, val_acc = train(emo_dim)\n",
    "#     print(f'->epoch:{epoch:3d}, train_loss={train_loss:.6f}, train_acc={train_acc:.4f}, val_loss={val_loss:.6f}, val_acc={val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8964d82-e4ca-40db-ad83-0722b8a6b880",
   "metadata": {},
   "source": [
    "## 比较实验\n",
    "### GCN\n",
    "+ 仅包括自环时，->epoch:25, train_loss:0.000922, train_acc:0.990784, test_loss:0.010875, test_acc:0.919401\n",
    "+ 加上3x3卷积核的邻接边时，->epoch:32, train_loss:0.000819, train_acc:0.992173, test_loss:0.020655, test_acc:0.895313，邻接边设计的不好，限制了模型的发挥\n",
    "+ 别人的方法的准确率：89/90、93/94\n",
    "### GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06f4ff-9fbb-4323-ad0d-4dfc7848e4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "torchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
