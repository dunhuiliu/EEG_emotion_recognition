{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bd6df28-9919-4bff-8e9a-ea82c35eba11",
   "metadata": {},
   "source": [
    "### 脑电图注意力网络（GAT）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8a2f88-794f-41ec-8149-bc8a5e11166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import add_self_loops, degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d86c9a-a9b3-496d-a650-e4b4c054fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def data_split(train_ratio=0.7):\n",
    "#     load_dir = '../global_data/time_76800x32x128/'\n",
    "\n",
    "#     trials = np.load(load_dir + 'trials.npy')\n",
    "#     bases = np.load(load_dir + 'bases.npy')\n",
    "#     labels = np.load(load_dir + 'labels.npy')\n",
    "#     # print(trials.shape, bases.shape, labels.shape)\n",
    "    \n",
    "#     # 去基线\n",
    "#     for i, base in enumerate(bases):\n",
    "#         trials[i * 60 : (i + 1) * 60] -= base\n",
    "    \n",
    "#     # 离散化标签\n",
    "#     labels = np.where(labels >= 5, 1, 0)\n",
    "\n",
    "#     # 复制标签以对齐样本\n",
    "#     labels = np.repeat(labels, 60, axis = 0)\n",
    "#     # print(labels.shape)\n",
    "    \n",
    "#     shuffle_list = np.arange(trials.shape[0])\n",
    "#     np.random.shuffle(shuffle_list)\n",
    "#     trials = trials[shuffle_list]\n",
    "#     labels = labels[shuffle_list]\n",
    "    \n",
    "#     cut_point = int(trials.shape[0] * train_ratio)\n",
    "#     train_features, train_labels = trials[:cut_point], labels[:cut_point]\n",
    "#     test_features, test_labels = trials[cut_point:], labels[cut_point:]\n",
    "    \n",
    "#     train_features = train_features.reshape((cut_point, 32 * 128))\n",
    "#     test_features = test_features.reshape((trials.shape[0] - cut_point, 32 * 128))\n",
    "    \n",
    "#     mean = train_features.mean(axis = 0)\n",
    "#     std = train_features.std(axis = 0)\n",
    "    \n",
    "#     train_features = (train_features - mean) / std\n",
    "#     test_features = (test_features - mean) / std\n",
    "    \n",
    "#     train_features = train_features.reshape((cut_point, 32, 128))\n",
    "#     test_features = test_features.reshape((trials.shape[0] - cut_point, 32, 128))\n",
    "    \n",
    "#     save_dir = 'data/data_split/'\n",
    "#     np.save(save_dir + 'train_features.npy', train_features)\n",
    "#     np.save(save_dir + 'train_labels.npy', train_labels)\n",
    "#     np.save(save_dir + 'test_features.npy', test_features)\n",
    "#     np.save(save_dir + 'test_labels.npy', test_labels)\n",
    "\n",
    "# data_split(train_ratio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb3182e-f053-4458-b057-bfd300617f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(is_train_data=True):\n",
    "    save_dir = 'data/data_split/'\n",
    "    if is_train_data:\n",
    "        features = np.load(save_dir + 'train_features.npy')\n",
    "        labels = np.load(save_dir + 'train_labels.npy')\n",
    "    else:\n",
    "        features = np.load(save_dir + 'test_features.npy')\n",
    "        labels = np.load(save_dir + 'test_labels.npy')\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b5e808-1250-4784-b6b7-a0e58d86017a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_edge_index(create_complete_graph=False, self_loop_only=False):\n",
    "    edge_index = [[],[]]\n",
    "    weight = []\n",
    "    \n",
    "    if create_complete_graph:\n",
    "        for i in range(32):\n",
    "            for j in range(32):\n",
    "                edge_index[0].append(i)\n",
    "                edge_index[1].append(j)\n",
    "        edge_index = torch.tensor(np.array(edge_index), dtype=torch.long)\n",
    "        return edge_index\n",
    "    \n",
    "    \n",
    "    if self_loop_only:\n",
    "        edge_index = torch.tensor(np.array(edge_index), dtype=torch.long)\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=32)\n",
    "        return edge_index\n",
    "    \n",
    "    adjacency_edge = {\n",
    "        1:[2],\n",
    "        2:[3, 19],\n",
    "        3:[5, 6],\n",
    "        4:[5],\n",
    "        5:[8, 7],\n",
    "        6:[7, 24],\n",
    "        7:[9, 10],\n",
    "        8:[9],\n",
    "        9:[12, 11],\n",
    "        10:[11, 16],\n",
    "        11:[13],\n",
    "        12:[],\n",
    "        13:[14, 15],\n",
    "        14:[15],\n",
    "        15:[],\n",
    "        16:[13, 31],\n",
    "        17:[18],\n",
    "        18:[19, 20],\n",
    "        19:[6, 23],\n",
    "        20:[23, 22],\n",
    "        21:[22],\n",
    "        22:[25, 26],\n",
    "        23:[24, 25],\n",
    "        24:[10, 28],\n",
    "        25:[28, 27],\n",
    "        26:[27],\n",
    "        27:[29, 30],\n",
    "        28:[16, 29],\n",
    "        29:[31],\n",
    "        30:[],\n",
    "        31:[15, 32],\n",
    "        32:[15]\n",
    "    }\n",
    "    \n",
    "    for start, end_list in adjacency_edge.items():\n",
    "        if len(end_list) == 0:\n",
    "            continue\n",
    "        for end in end_list:\n",
    "            edge_index[0].append(start - 1)\n",
    "            edge_index[1].append(end - 1)\n",
    "            edge_index[0].append(end - 1)\n",
    "            edge_index[1].append(start - 1)\n",
    "           \n",
    "    edge_index = torch.tensor(np.array(edge_index), dtype=torch.long)\n",
    "    \n",
    "    edge_index, _ = add_self_loops(edge_index, num_nodes=32)\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd42b5bf-ca24-4f71-95ad-b0b494aaa18f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_edge_index(create_complete_graph=False, self_loop_only=False):\n",
    "    edge_index = [[],[]]\n",
    "    weight = []\n",
    "    \n",
    "    if self_loop_only:\n",
    "        edge_index = torch.tensor(np.array(edge_index), dtype=torch.long)\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=32)\n",
    "        return edge_index\n",
    "    \n",
    "    adjacency_edge = {\n",
    "        1:[2],\n",
    "        2:[3, 19],\n",
    "        3:[5, 6],\n",
    "        4:[5],\n",
    "        5:[8, 7],\n",
    "        6:[7, 24],\n",
    "        7:[9, 10],\n",
    "        8:[9],\n",
    "        9:[12, 11],\n",
    "        10:[11, 16],\n",
    "        11:[13],\n",
    "        12:[],\n",
    "        13:[14, 15],\n",
    "        14:[15],\n",
    "        15:[],\n",
    "        16:[13, 31],\n",
    "        17:[18],\n",
    "        18:[19, 20],\n",
    "        19:[6, 23],\n",
    "        20:[23, 22],\n",
    "        21:[22],\n",
    "        22:[25, 26],\n",
    "        23:[24, 25],\n",
    "        24:[10, 28],\n",
    "        25:[28, 27],\n",
    "        26:[27],\n",
    "        27:[29, 30],\n",
    "        28:[16, 29],\n",
    "        29:[31],\n",
    "        30:[],\n",
    "        31:[15, 32],\n",
    "        32:[15]\n",
    "    }\n",
    "    \n",
    "    for start, end_list in adjacency_edge.items():\n",
    "        if len(end_list) == 0:\n",
    "            continue\n",
    "        for end in end_list:\n",
    "            edge_index[0].append(start - 1)\n",
    "            edge_index[1].append(end - 1)\n",
    "            edge_index[0].append(end - 1)\n",
    "            edge_index[1].append(start - 1)\n",
    "           \n",
    "    edge_index = torch.tensor(np.array(edge_index), dtype=torch.long)\n",
    "    \n",
    "    edge_index, _ = add_self_loops(edge_index, num_nodes=32)\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fcb8368-b508-41fb-baa4-5e35d16ff337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index = [[],[]]\n",
    "# weight = []\n",
    "\n",
    "# #用一个字典保存 通道下标对应 9 * 9 矩阵的下标\n",
    "# chan_to_1020={0:[0,3],1:[1,3],2:[2,2],3:[2,0],4:[3,1],5:[3,3],6:[4,2],7:[4,0],8:[5,1],\n",
    "#               9:[5,3],10:[6,2],11:[6,0],12:[7,3],13:[8,3],14:[8,4],15:[6,4],16:[0,5],\n",
    "#               17:[1,5],18:[2,4],19:[2,6],20:[2,8],21:[3,7],22:[3,5],23:[4,4],24:[4,6],\n",
    "#                 25:[4,8],26:[5,7],27:[5,5],28:[6,6],29:[6,8],30:[7,5],31:[8,5]}\n",
    "# maps = np.zeros(shape=(9, 9), dtype=int)\n",
    "\n",
    "# for k, v in chan_to_1020.items():\n",
    "#     maps[v[0]][v[1]] = k + 1\n",
    "# print(maps)\n",
    "# plt.matshow(maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d5064c8-5b77-4c0a-8056-45b125c07195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data, Dataset\n",
    "\n",
    "class MyDataset(InMemoryDataset):\n",
    "    is_train_data = None\n",
    "    edge_index = None\n",
    "    def __init__(self, root, is_train_data, edge_index):\n",
    "        self.is_train_data = is_train_data\n",
    "        self.edge_index = edge_index\n",
    "        super(MyDataset, self).__init__(root)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    \n",
    "    # 检查self.processed_dir目录下是否存在self.processed_file_names属性方法返回的所有文件，没有就会走process\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        if self.is_train_data:\n",
    "            return ['train.dataset']\n",
    "        return ['test.datset']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        features, labels = None, None\n",
    "        \n",
    "        if self.is_train_data:\n",
    "            features, labels = load_data(is_train_data=True)\n",
    "        else:\n",
    "            features, labels = load_data(is_train_data=False)\n",
    "        \n",
    "        data_list = []\n",
    "        for i in range(features.shape[0]):\n",
    "            x = torch.tensor(features[i], dtype=torch.float)\n",
    "            y = torch.tensor(labels[i].reshape(1, -1), dtype=torch.long)\n",
    "            data = Data(x = x, edge_index=self.edge_index, y=y)\n",
    "            data_list.append(data)\n",
    "        data, slices = self.collate(data_list)\n",
    "        \n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379387d3-85fb-4d21-80cc-4541f55a331f",
   "metadata": {},
   "source": [
    "+ data.x: Node feature matrix with shape [num_nodes, num_node_features]\n",
    "\n",
    "+ data.edge_index: Graph connectivity in COO format with shape [2, num_edges] and type torch.long\n",
    "\n",
    "+ data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n",
    "\n",
    "+ data.y: Target to train against (may have arbitrary shape), e.g., node-level targets of shape [num_nodes, *] or graph-level targets of shape [1, *]\n",
    "\n",
    "+ data.pos: Node position matrix with shape [num_nodes, num_dimensions]\n",
    "\n",
    "--- \n",
    "\n",
    "- train_mask denotes against which nodes to train (140 nodes),\n",
    "\n",
    "- val_mask denotes which nodes to use for validation, e.g., to perform early stopping (500 nodes),\n",
    "\n",
    "- test_mask denotes against which nodes to test (1000 nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0803e6-269e-4f79-832b-315ec6ea89cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import TopKPooling, SAGEConv, GCNConv, GATConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "embed_dim = 128\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        \n",
    "        self.temporalMLPs1 = []\n",
    "        \n",
    "        for i in range(32):\n",
    "            self.temporalMLPs1.append(nn.Linear(128, 256, device=device))\n",
    "        \n",
    "        self.temporalMLPs2 = []\n",
    "        \n",
    "        for i in range(32):\n",
    "            self.temporalMLPs2.append(nn.Linear(256, 256, device=device))\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(8192, 512)\n",
    "        self.lin2 = torch.nn.Linear(512, 128)\n",
    "        self.lin3 = torch.nn.Linear(128, 2)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # x： n * 1, 其中每个图中点的个数是不同的\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        batch_size = data.y.shape[0]\n",
    "        x = x.view(batch_size, 32, 128)\n",
    "        \n",
    "        temporalMLPs_out = []\n",
    "        \n",
    "        for i in range(32):\n",
    "            x1 = self.temporalMLPs1[i](x[:, i, :])\n",
    "            x1 = F.relu(x1)\n",
    "            x1 = F.dropout(x1, 0.2)\n",
    "            x1 = self.temporalMLPs2[i](x1)\n",
    "            x1 = F.relu(x1)\n",
    "            x1 = F.dropout(x1, 0.2)\n",
    "            temporalMLPs_out.append(x1)\n",
    "        \n",
    "        # concat\n",
    "        x = torch.concat(temporalMLPs_out, dim = 1)\n",
    "        \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "#         x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50636f52-fc65-4f4a-94e1-2e79dd89b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(emo_dim):\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch_id, batch in enumerate(trainDataLoader):\n",
    "        batch.to(device)\n",
    "        opt.zero_grad()\n",
    "        output = model(batch)\n",
    "        loss = crit(output, batch.y[:, emo_dim])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        output = torch.max(output, 1)[1]\n",
    "        train_acc += (output == batch.y[:, emo_dim]).sum()\n",
    "    \n",
    "    num_train_sample = len(trainDataLoader.dataset)\n",
    "    train_loss = train_loss / num_train_sample\n",
    "    train_acc = train_acc / num_train_sample\n",
    "    \n",
    "    # check测试集的性能\n",
    "    vali_loss = 0\n",
    "    vali_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for batch in testDataLoader:\n",
    "        batch.to(device)\n",
    "        output = model(batch)\n",
    "        loss = crit(output, batch.y[:, emo_dim])\n",
    "        vali_loss += loss.item()\n",
    "        output = torch.max(output, 1)[1]\n",
    "        vali_acc += (output == batch.y[:, emo_dim]).sum()\n",
    "    \n",
    "    num_test_sample = len(testDataLoader.dataset)\n",
    "    vali_loss = vali_loss / num_test_sample\n",
    "    vali_acc = vali_acc / num_test_sample\n",
    "    \n",
    "    print(f'train_loss:{train_loss:.6f}, train_acc:{train_acc:.6f}, test_loss:{vali_loss:.6f}, test_acc:{vali_acc:.6f}')\n",
    "    \n",
    "    return train_loss, train_acc, vali_loss, vali_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f9bf77-c20d-484b-932b-8b98917f374b",
   "metadata": {},
   "source": [
    "# 超参设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd1e1611-fac8-4210-b800-bf02914ed6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_complete_graph = False\n",
    "self_loop_only = False\n",
    "emo_dim = 0\n",
    "batch_size = 32\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f54215ce-14bd-4072-bbd2-c16971a9f9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "edge_index = get_edge_index(create_complete_graph=create_complete_graph, self_loop_only=self_loop_only)\n",
    "\n",
    "trainData = MyDataset(root='data/data_split', is_train_data=True, edge_index=edge_index)\n",
    "trainDataLoader = DataLoader(trainData, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testData = MyDataset(root='data/data_split', is_train_data=False, edge_index=edge_index)\n",
    "testDataLoader = DataLoader(testData, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef3f3d55-fc83-475e-a697-9b8a12789830",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAT().to(device)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "crit = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5d67c7-8ea4-4e5d-aff1-4f2b832d6101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->epoch:1, train_loss:0.018787, train_acc:0.668287, test_loss:0.016049, test_acc:0.747135\n",
      "->epoch:2, train_loss:0.013750, train_acc:0.792549, test_loss:0.012537, test_acc:0.817708\n",
      "->epoch:3, "
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    print(f'->epoch:{epoch + 1}', end = ', ')\n",
    "    train_loss, train_acc, val_loss, val_acc = train(emo_dim)\n",
    "#     print(f'->epoch:{epoch:3d}, train_loss={train_loss:.6f}, train_acc={train_acc:.4f}, val_loss={val_loss:.6f}, val_acc={val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aaaa6f-c3fb-4b07-91b9-aa185cf2b0ba",
   "metadata": {},
   "source": [
    "- MLP_base ->epoch:195, train_loss:0.000070, train_acc:0.999494, test_loss:0.022968, test_acc:0.933854\n",
    "- MLP_2层dropout（p=0.2）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa21ed2-da43-4dc3-ad70-081231e98ef4",
   "metadata": {},
   "source": [
    "# 增加模型容量\n",
    "- ->epoch:86, train_loss:0.002378, train_acc:0.980787, test_loss:0.017223, test_acc:0.908203\n",
    "- 改为heads=3， ->epoch:167, train_loss:0.001960, train_acc:0.985171, test_loss:0.022945, test_acc:0.910417"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8964d82-e4ca-40db-ad83-0722b8a6b880",
   "metadata": {},
   "source": [
    "## 比较实验\n",
    "### GCN\n",
    "+ 仅包括自环时，->epoch:25, train_loss:0.000922, train_acc:0.990784, test_loss:0.010875, test_acc:0.919401\n",
    "+ 加上3x3卷积核的邻接边时，->epoch:32, train_loss:0.000819, train_acc:0.992173, test_loss:0.020655, test_acc:0.895313，邻接边设计的不好，限制了模型的发挥\n",
    "+ 别人的方法的准确率：89/90、93/94\n",
    "### GAT\n",
    "+ 仅包括自环时，->epoch:30, train_loss:0.001252, train_acc:0.986531, test_loss:0.015308, test_acc:0.912630\n",
    "+ 使用自己设计的边，->epoch:123, train_loss:0.002104, train_acc:0.982161, test_loss:0.029411, test_acc:0.904688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06f4ff-9fbb-4323-ad0d-4dfc7848e4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "torchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
