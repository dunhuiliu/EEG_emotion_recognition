{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pywt import wavedec\n",
    "import pandas as pd\n",
    "from scipy.fftpack import fft,ifft\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import joblib\n",
    "import pywt.data\n",
    "import pickle as pickle\n",
    "import random\n",
    "from pywt import wavedec\n",
    "import math\n",
    "import pyeeg as pe\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取Deap数据的EEG信号\\n\n",
    "#设置全局变量\n",
    "channel=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32]#前32个通道为脑电信号\n",
    "# channel=[1]#前32个通道为脑电信号\n",
    "band = [4,8,12,16,25,45] #5 bands\n",
    "subjectList= ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32']\n",
    "# subjectList= ['01']\n",
    "\n",
    "\n",
    "window_size = 128 #Averaging band power of 2 sec\n",
    "step_size = 128 #Each 0.125 sec update once\n",
    "sample_rate = 128 #Sampling rate of 128 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算前三秒的基线特征数据 求前三秒的基线平均值\n",
    "def Base(sub, channel):\n",
    "        print(\"样本人基线\",sub)\n",
    "        with open('data\\s'+sub+'.dat','rb')as file:\n",
    "            subject = pickle.load(file, encoding='latin1')\n",
    "            baseAll = [] #保存前三秒静默时间特征基线 3*160*40\n",
    "            for i in range(0, 40):  # 循环遍历0-40个素材数据\\n\", \n",
    "                base = []#保存前三秒静默时间特征基线 \n",
    "                baseStart = 0\n",
    "                while baseStart + sample_rate <= 384:\n",
    "                    base_data=[]\n",
    "                    for j in channel:\n",
    "                        basedata = subject[\"data\"][i]\n",
    "                        basechannelData=basedata[j]\n",
    "                        baseX = basechannelData[baseStart : baseStart + sample_rate] #Slice raw data over 2 sec, at interval of 0.125 sec\n",
    "                        baseY = pe.bin_power(baseX, band, sample_rate) #FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\n",
    "                        base_data = base_data + list(np.log2(baseY[0]))\n",
    "                    base.append(base_data)\n",
    "                    baseStart = baseStart + sample_rate\n",
    "#                 print(np.array(base).shape)\n",
    "                basemean=np.array(base).mean(axis=0)\n",
    "#                 print(np.array(basemean))\n",
    "                baseAll.append(basemean)\n",
    "            print(len(baseAll))\n",
    "            return baseAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "样本人基线 01\n",
      "40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-419f35c82c0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m                         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Slice raw data over 2 sec, at interval of 0.125 sec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbin_power\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mband\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                         \u001b[0mmeta_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_data\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\svmData\\pyeeg\\spectrum.py\u001b[0m in \u001b[0;36mbin_power\u001b[1;34m(X, Band, Fs)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mPower\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBand\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mfft\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mE:\\mth\\Anaconda3\\lib\\site-packages\\numpy\\fft\\_pocketfft.py\u001b[0m in \u001b[0;36mfft\u001b[1;34m(a, n, axis, norm)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0m_unitary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0minv_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_raw_fft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minv_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\mth\\Anaconda3\\lib\\site-packages\\numpy\\fft\\_pocketfft.py\u001b[0m in \u001b[0;36m_raw_fft\u001b[1;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpfi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#random\n",
    "str = 'people23/'\n",
    "result = []\n",
    "index = 0\n",
    "RESULT = []\n",
    "subjectList= ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32']\n",
    "\n",
    "\n",
    "for subjects in subjectList:\n",
    "    print(subjects)\n",
    "    dataTraining = []\n",
    "    labelTraining = []\n",
    "    dataTest = []\n",
    "    labelTest = []\n",
    "    dataVal = []\n",
    "    labelval = []\n",
    "    base = Base(subjects,channel)\n",
    "    with open('data\\s' + subjects + '.dat', 'rb') as file:\n",
    "            subject = pickle.load(file, encoding='latin1')\n",
    "            \n",
    "            for i in range(0, 40):  # 循环遍历0-40个素材数据\\n\",\n",
    "                data = subject[\"data\"][i]\n",
    "                labels = subject[\"labels\"][i]\n",
    "                nlabel = 0\n",
    "                if labels[0]>=5:\n",
    "                    nlabel = 1\n",
    "                      \n",
    "                start = 384\n",
    "                count =0\n",
    "                \n",
    "                randomhighNum = 10\n",
    "                testList=random.sample(range(0,60),randomhighNum)\n",
    "                #验证集\n",
    "                leftList=[index for index in range(0,60) if index not in testList]\n",
    "                ValList=random.sample(list(leftList),randomhighNum)   \n",
    "               \n",
    "                trainList = [index for index in leftList if index not in ValList]\n",
    "              \n",
    "               \n",
    "            \n",
    "                while start + window_size <= 8064: # 使用窗口将每个通道的信号分为464份，可以产生464个样本（去掉前3秒的数据）\n",
    "                    meta_array = []\n",
    "                    meta_data = [] #meta vector for analysis\n",
    "                    for j in channel:\n",
    "                       \n",
    "                       \n",
    "                        X =  data[j][start : start + window_size] #Slice raw data over 2 sec, at interval of 0.125 sec\n",
    "\n",
    "                        Y = pe.bin_power(X, band, sample_rate) #FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\n",
    "                     \n",
    "                        meta_data = meta_data + list(np.log2(Y[0]))\n",
    "\n",
    "                    if count in trainList:\n",
    "                         dataTraining.append(np.array(meta_data-base[i]))\n",
    "                         labelTraining.append(nlabel)\n",
    "                        \n",
    "                    elif count in ValList:\n",
    "                        dataVal.append(np.array(meta_data-base[i]))\n",
    "                        labelval.append(nlabel)\n",
    "                    else:\n",
    "                        dataTest.append(np.array(meta_data-base[i]))\n",
    "                        labelTest.append(nlabel)\n",
    "                                        \n",
    "                    count = count + 1\n",
    "                    start = start + step_size\n",
    "\n",
    "    np.save(str+ subjects  + '/dataTest', np.array(dataTest), allow_pickle=True, fix_imports=True)\n",
    "    np.save(str+ subjects  + '/labelTest', np.array(labelTest), allow_pickle=True, fix_imports=True)\n",
    "    np.save(str+ subjects  + '/dataTraining', np.array(dataTraining), allow_pickle=True, fix_imports=True)\n",
    "    np.save(str+ subjects  + '/labelTraining', np.array(labelTraining), allow_pickle=True, fix_imports=True)\n",
    "    np.save(str+ subjects  + '/dataVal', np.array(dataVal), allow_pickle=True, fix_imports=True)\n",
    "    np.save(str+ subjects  + '/labelval', np.array(labelval), allow_pickle=True, fix_imports=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    X  = np.array(dataTraining)\n",
    "    print(X.shape)\n",
    "    X = normalize(X)\n",
    "    #print(X.shape)\n",
    "    Z = labelTraining\n",
    "\n",
    "    M  =  np.array(dataVal)\n",
    "    M = normalize(M)\n",
    "    L = labelval\n",
    "\n",
    "    val_r = svm.SVC()\n",
    "    val_r.fit(X,Z)\n",
    "    accV = val_r.score(M,L)\n",
    "    \n",
    "    \n",
    "    E  =  np.array(dataTest)\n",
    "    E = normalize(E)\n",
    "    F = labelTest\n",
    "\n",
    "    accT = val_r.score(E,F)\n",
    "    \n",
    "    result.append(accV)\n",
    "    RESULT.append(accT)\n",
    "    print(accV,accT)\n",
    "print(\"mean\",np.mean(result),np.mean(RESULT))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
