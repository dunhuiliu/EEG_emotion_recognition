{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/wlgls/Desktop/DEAP/data_preprocessed_python/s01.dat\"\n",
    "with open(path, \"rb\") as f:\n",
    "    subject = pickle.load(f, encoding='latin1')\n",
    "\n",
    "data = subject['data']\n",
    "label = subject['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 40, 8064), (40, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取32个通道，第一个标签\n",
    "data = data[:, :32]\n",
    "label = label[:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 32, 8064), (40, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签二值化\n",
    "label[label<=5] = 0\n",
    "label[label >5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_signal(data, label, windows=1, fs=128):\n",
    "    \"\"\"In the study, We divided a trial into 60 seconds. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array\n",
    "        data, for DEAP dataset, It's shape may be (n_trials, n_channels, points) \n",
    "    label : array\n",
    "        In order to correspond with data\n",
    "    windows : int, optional\n",
    "        Window size of segmentation, by default 1\n",
    "    sf : int, optional\n",
    "        sampling frequency, by default 128\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tmpData:\n",
    "        Sliced data, If your input's shape is (n_trials, n_channels, points), The tmpData.shape is (n_trials, points//(windows*fs), n_channels, windows*fs)\n",
    "    tmpLabel:\n",
    "        Corresponding with data. It's shape maybe (n_trials, points//(windows*fs))\n",
    "    \n",
    "    Examples:\n",
    "    ----------\n",
    "    In [16]: data.shape, label.shape\n",
    "    Out[16]: ((40, 32, 8064), (40, 1))\n",
    "\n",
    "    In [17]: d, l = split_signal(data, label)\n",
    "\n",
    "    In [18]: d.shape, l.shape\n",
    "    Out[18]: ((40, 63, 32, 128), (40, 63))\n",
    "    \"\"\"\n",
    "    if len(data.shape) != 3:\n",
    "        raise ValueError\n",
    "\n",
    "    sp = data.shape[-1] // fs // windows\n",
    "    tmpData = np.stack(np.split(data, sp, axis=2), axis=1)\n",
    "    tmpLabel = np.repeat(label, tmpData.shape[1], axis=1)\n",
    "    return tmpData, tmpLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 将8064 63s的数据按照一秒的窗口分割\n",
    "d, l =split_signal(data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 63, 32, 128), (40, 63))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第二个维度 63s小片段, 每个片段32个通道，每个通道128个采样点\n",
    "# 标签就是重复了63次\n",
    "d.shape, l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "### 看看对不对，\n",
    "print(np.any(d[0, 0, 0] == data[0, 0, :128]))# 第1个影片，第1s，第一个通道\n",
    "print(np.any(d[1, 40, 20] == data[1, 20, 128*40:128*41])) # 第2个影片，第40s， 第20个通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_baseline(data, label, baseline=3):\n",
    "    \"\"\"For the deap dataset, the first three seconds are the baseline, we need to get rid of it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array\n",
    "        data, for sliced DEAP dataset, It's shape may be (n_trials, n_slices,  n_channels, points) \n",
    "    label : array\n",
    "        In order to correspond with data\n",
    "    baseline : int, optional\n",
    "        Baseline time, by default 3\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    base:\n",
    "        Baseline\n",
    "    signal:\n",
    "        Remove baseline data.It's shape maybe (n_trials, n_slices-baseline, n_channels, points)\n",
    "    \"\"\"\n",
    "    base = data[:, :baseline, ...]\n",
    "    signal = data[:, baseline:, ...]\n",
    "\n",
    "    base_label = label[:, :baseline]\n",
    "    signal_label = label[:, baseline:]\n",
    "\n",
    "    return base, base_label, signal, signal_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据分为基线和实际观影信号，前3秒就是基线\n",
    "base, baselabel, signalx, signallabel = remove_baseline(d, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 3, 32, 128), (40, 3), (40, 60, 32, 128), (40, 60))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.shape, baselabel.shape, signalx.shape, signallabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_spectral_density(data, sf=128, nperseg=128, band=(4, 8, 14, 31, 65)):\n",
    "    \"\"\"The power of each frequency band is calculated according to the frequency band division，and then it combines the frequency band power into a feature vector. It mainly uses Welch method.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array\n",
    "        data, for DEAP dataset, It's shape may be (n_trials,n_slices, n_channels, points) （40, 63, 32, 128）\n",
    "    sf : int, optional\n",
    "        sampling frequency, by default 128\n",
    "    nperseg : int, optional\n",
    "        for Welch method, According to scipy.signal.welch , by default 1\n",
    "    band : tuple, optional\n",
    "        boundary frequencies of bands, by default (4, 8, 14, 31, 65)\n",
    "        e.g. for (4, 8, 14, 31, 65), It will calculate the power spectrum of theta(4~7Hz),alpha(8~13Hz),beta(14~30Hz) and gamma(31~64Hz).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    f:\n",
    "        Solved feature, It's shape is similar to the shape of your input data.\n",
    "        e.g. for input.shape is (n_trials,n_slices n_channels, points), the f.shape is (n_trials,n_slices, n_channels, n_features)\n",
    "    \n",
    "    Example\n",
    "    ------\n",
    "    In [5]: d, l = load_deap(path, 0)\n",
    "\n",
    "    In [6]: d.shape, l.shape\n",
    "    Out[6]: ((40, 32, 8064), (40, 1))\n",
    "\n",
    "    In [7]: psd(d).shape\n",
    "    Out[7]: (40, 32, 5) # Each channel has 5 bands of average power\n",
    "    \n",
    "    In [12]: d, l = split_signal(d, l)\n",
    "\n",
    "    In [13]: d.shape, l.shape\n",
    "    Out[13]: ((40, 63, 32, 128), (40, 63))\n",
    "\n",
    "    In [14]: psd(d).shape\n",
    "    Out[14]: (40, 63, 32, 4)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    band = np.array(band)\n",
    "\n",
    "    freqs, power = signal.welch(data, sf, nperseg=nperseg)\n",
    "    \n",
    "    freqband = np.hsplit(freqs, band)[1:-1] # Remove the beginning and the end\n",
    "\n",
    "    # Get the index of the corresponding frequency band\n",
    "    pindex = []\n",
    "    for fb in freqband:\n",
    "        pindex.append(np.where(np.in1d(freqs, fb))[0])\n",
    "    \n",
    "    # Get features\n",
    "    f = []\n",
    "    for index in pindex:\n",
    "        f.append(np.mean(power[..., index], axis=-1))\n",
    "    \n",
    "    f = np.stack(f, axis=-1)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求解特征\n",
    "basef = power_spectral_density(base)# 基线\n",
    "signalf = power_spectral_density(signalx) # 信号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 3, 32, 4), (40, 60, 32, 4))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basef.shape, signalf.shape # 每个通道提出来4个频道功率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_electrode(features):\n",
    "    \n",
    "    return features.reshape((*features.shape[:-2], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将他们按照通道推起来\n",
    "basef = combined_electrode(basef)\n",
    "signalf = combined_electrode(signalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 3, 128), (40, 60, 128))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basef.shape, signalf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 减去基线 对基线求平均后减掉\n",
    "base_mean = np.mean(basef, axis=1)[:, np.newaxis, :]\n",
    "psdf = signalf - base_mean\n",
    "psdY = signallabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 60, 128), (40, 60))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf.shape, psdY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_time(data, label, shuffle=False):\n",
    "    \"\"\"It may be wrong. In the study, We divided a trial into 60 seconds. For 40 trials, We may choose some time for the training set, the rest is for test set. So we need to group data by time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array\n",
    "        data, for sliced DEAP dataset, It's shape may be (n_trials, n_slices,  n_features) \n",
    "    label : array\n",
    "        Similarly, we need to map labels to data\n",
    "    shuffle : bool, optional\n",
    "        shuffle, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    groups: array\n",
    "        Your group\n",
    "    data: array\n",
    "        Data after grouping. If your input's shape is (n_trials*n_slices,  n_features) \n",
    "    label: array\n",
    "        Label after grouping.\n",
    "    \"\"\"\n",
    "    trials, slices, *features_shape = data.shape\n",
    "    data = data.reshape(-1, *features_shape)\n",
    "    label = label.reshape(-1)\n",
    "\n",
    "    groups = np.arange(1, slices+1)\n",
    "    groups = np.tile(groups, trials)\n",
    "\n",
    "    if shuffle:\n",
    "        index = np.arange(len(groups))\n",
    "        np.random.shuffle(index)\n",
    "        return groups[index], data[index], label[index]\n",
    "    \n",
    "    return groups, data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据分组, 就是说一个试验60s,分成60个片段，那么第一个片段就属于第一组，第二个片段就属于第二组\n",
    "G, X, Y = group_by_time(psdf, psdY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400,), (2400, 128), (2400,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.shape, X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60,  1,  2,  3,  4,  5,  6,  7,  8,\n",
       "        9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
       "       26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
       "       43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n",
       "       60])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G[:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 测试分组正确否\n",
    "print(np.any(X[:60] == psdf[0]))\n",
    "print(np.any(X[60:120]== psdf[1]))\n",
    "print(np.any(X[60*8:60*9] == psdf[8]))\n",
    "\n",
    "print(np.any(Y[:60] == psdY[0]))\n",
    "print(np.any(Y[60:120] == psdY[1]))\n",
    "print(np.any(Y[60*8:60*9] == psdY[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照秒来划分数据集\n",
    "# 比如前40s做训练集，后20秒做测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_G = np.arange(1, 41)\n",
    "test_G = np.arange(41, 61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "        35, 36, 37, 38, 39, 40]),\n",
       " array([41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
       "        58, 59, 60]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_G, test_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = np.in1d(G, train_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index = np.in1d(G, test_G)\n",
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = X[test_index], Y[test_index]\n",
    "X_train, Y_train = X[train_index], Y[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380 420\n",
      "760 840\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(Y_test == 1), np.sum(Y_test == 0))\n",
    "print(np.sum(Y_train == 1), np.sum(Y_train == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, Y_train)\n",
    "rfc.score(X_test, Y_test)# hhhh, 我也不知道为什么会达到98%, 这次结果比上次还离谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###完整程序\n",
    "path = \"/home/wlgls/Desktop/DEAP/data_preprocessed_python/s01.dat\"\n",
    "with open(path, \"rb\") as f:\n",
    "    subject = pickle.load(f, encoding='latin1')\n",
    "\n",
    "data = subject['data']\n",
    "label = subject['labels']\n",
    "\n",
    "# 取32个通道，第一个标签\n",
    "data = data[:, :32]\n",
    "label = label[:, :1]\n",
    "\n",
    "# 标签二值化\n",
    "label[label<=5] = 0\n",
    "label[label >5] = 1\n",
    "\n",
    "### 将8064 63s的数据按照一秒的窗口分割\n",
    "d, l =split_signal(data, label)\n",
    "\n",
    "# 将数据分为基线和实际观影信号，前3秒就是基线\n",
    "base, baselabel, signalx, signallabel = remove_baseline(d, l)\n",
    "\n",
    "# 求解特征\n",
    "basef = power_spectral_density(base)# 基线\n",
    "signalf = power_spectral_density(signalx) # 信号\n",
    "\n",
    "# 将他们按照通道推起来\n",
    "basef = combined_electrode(basef)\n",
    "signalf = combined_electrode(signalf)\n",
    "\n",
    "# 减去基线 对基线求平均后减掉\n",
    "base_mean = np.mean(basef, axis=1)[:, np.newaxis, :]\n",
    "psdf = signalf - base_mean\n",
    "psdY = signallabel\n",
    "\n",
    "# 对数据分组, 就是说一个试验60s,分成60个片段，但是属于一个试验\n",
    "G, X, Y = group_by_time(psdf, psdY)\n",
    "\n",
    "# 按照秒来划分数据集\n",
    "# 比如前40s做训练集，后20秒做测试集\n",
    "train_G = np.arange(1, 41)\n",
    "test_G = np.arange(41, 61)\n",
    "\n",
    "# 获得训练集和测试集所在位置\n",
    "train_index = np.in1d(G, train_G)\n",
    "test_index = np.in1d(G, test_G)\n",
    "\n",
    "X_test, Y_test = X[test_index], Y[test_index]\n",
    "X_train, Y_train = X[train_index], Y[train_index]\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rfc.fit(X_train, Y_train)\n",
    "rfc.score(X_test, Y_test)# hhhh, 我也不知道为什么会达到98%, 这次结果比上次还离谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
