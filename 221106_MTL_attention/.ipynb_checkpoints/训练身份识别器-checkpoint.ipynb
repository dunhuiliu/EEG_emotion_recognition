{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9dbd5b7-7730-4ceb-a7c8-5803799f39a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e49be2b-7d9f-41b3-a34f-e570b2344561",
   "metadata": {},
   "source": [
    "#### TODO: 用第一个人的网络，测试第二个人，性能怎么样？\n",
    "    如果性能不好，就说明自己用自己的网络性能好，所以在训练多任务网络时，就应该鼓励受试者自己使用自己的网络\n",
    "#### 经过证明，性能确实不好，在40-60之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06b14e2-1602-476e-86dd-a80a1bde64e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76800, 128, 9, 9) (1280, 128, 9, 9) (1280, 2)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "load_path = '../global_data/76800x128x9x9/'\n",
    "\n",
    "trials = np.load(load_path + 'trials.npy')\n",
    "bases = np.load(load_path + 'bases.npy')\n",
    "labels = np.load(load_path + 'labels.npy')\n",
    "# chw格式\n",
    "print(trials.shape, bases.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07999f1-2ab1-4593-bc02-3431dd862492",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ac8020-c784-48f4-a744-34785e882662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76800, 128, 9, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去基线\n",
    "trials_de_base = []\n",
    "for i, base in enumerate(bases):\n",
    "    trials_de_base.append(trials[i * 60 : (i + 1) * 60] - base)\n",
    "trials_de_base = np.array(trials_de_base)\n",
    "trials_de_base = trials_de_base.reshape((-1, 128, 9, 9))\n",
    "print(trials_de_base.shape)\n",
    "\n",
    "# 离散化标签\n",
    "labels = np.where(labels >= 5, 1, 0)\n",
    "\n",
    "# 复制以对齐样本\n",
    "labels = np.repeat(labels, 60, axis = 0)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa93a8e4-84e0-4123-bba7-17017d455545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_split(features, labels, train_ratio = 0.9):\n",
    "    sample_cnt = labels.shape[0]\n",
    "    # 数据集划分\n",
    "    train_ratio = train_ratio\n",
    "    shuffer_list = np.arange(sample_cnt)\n",
    "    np.random.shuffle(shuffer_list)\n",
    "\n",
    "    features_shuffer = features[shuffer_list] # trials_de_base\n",
    "    labels_shuffer = labels[shuffer_list]\n",
    "\n",
    "    x_train = features_shuffer[:int(train_ratio * sample_cnt)]\n",
    "    y_train = labels_shuffer[:int(train_ratio * sample_cnt)]\n",
    "    x_test = features_shuffer[int(train_ratio * sample_cnt):]\n",
    "    y_test = labels_shuffer[int(train_ratio * sample_cnt):]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c13482-2a9a-4ada-ad9b-7aff8e426afc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def z_norm(x_train, x_test):# z归一化\n",
    "    chan_to_1020={0:[0,3],1:[1,3],2:[2,2],3:[2,0],4:[3,1],5:[3,3],6:[4,2],7:[4,0],8:[5,1],\n",
    "                  9:[5,3],10:[6,2],11:[6,0],12:[7,3],13:[8,3],14:[8,4],15:[6,4],16:[0,5],\n",
    "                  17:[1,5],18:[2,4],19:[2,6],20:[2,8],21:[3,7],22:[3,5],23:[4,4],24:[4,6],\n",
    "                    25:[4,8],26:[5,7],27:[5,5],28:[6,6],29:[6,8],30:[7,5],31:[8,5]}\n",
    "\n",
    "    # 需要归一化的位置\n",
    "    need_norm_pos = np.zeros(shape=(9,9), dtype=int)\n",
    "\n",
    "    for val in chan_to_1020.values():\n",
    "        need_norm_pos[val[0]][val[1]] = 1\n",
    "    # print(need_norm_pos)\n",
    "\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            if need_norm_pos[i][j] == 0:\n",
    "                continue\n",
    "            for t in range(128):\n",
    "                mean = np.mean(x_train[:, t, i, j])\n",
    "                std = np.std(x_train[:, t, i, j])\n",
    "                x_train[:, t, i, j] -= mean\n",
    "                x_train[:, t, i, j] /= std\n",
    "                x_test[:, t, i, j] -= mean\n",
    "                x_test[:, t, i, j] /= std\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0edca54f-4487-47d3-aea2-c979b47068ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参设置\n",
    "batch_size = 32\n",
    "max_epoch = 200\n",
    "emotion_dim = 0\n",
    "\n",
    "patient = 10\n",
    "\n",
    "model_save_path = 'model/transformer_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abfb40a5-74a2-4757-8cc3-582fa990983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94075f15-fcbe-4b43-b694-b32d17d8f82a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 0.000013, train_acc: 0.991667, vali_loss: 0.000206, vali_acc: 0.979167\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from IndiviTransNet import IndiviTransNet\n",
    "\n",
    "for sub_idx in range(32):\n",
    "    \n",
    "    model = IndiviTransNet()\n",
    "    # 初始化权重参数\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), 0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_loss_holder = []\n",
    "    vali_loss_holder = []\n",
    "\n",
    "    #损失值设为无限大，每次迭代若损失值比loss_value小则保存模型，并将最新的损失值赋给loss_value\n",
    "    acc_value=0\n",
    "    step=0\n",
    "    \n",
    "    sub_feature = trials_de_base[sub_idx * 2400 : (sub_idx + 1) * 2400]\n",
    "    sub_labels = labels[sub_idx * 2400 : (sub_idx + 1) * 2400]\n",
    "    x_train, y_train, x_test, y_test = data_split(sub_feature, sub_labels,train_ratio=0.9)\n",
    "    \n",
    "    x_train, x_test = z_norm(x_train, x_test)\n",
    "    y_train = y_train[:, emotion_dim]\n",
    "    y_test = y_test[:, emotion_dim]\n",
    "    \n",
    "    x_train = torch.tensor(x_train, dtype=torch.float)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    x_test = torch.tensor(x_test, dtype=torch.float)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    data_train = TensorDataset(x_train, y_train)\n",
    "#     data_test = TensorDataset(x_test, y_test)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=data_train, batch_size=batch_size, shuffle=True)\n",
    "#     test_loader = DataLoader(dataset=data_test, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for i in range(max_epoch):\n",
    "        for batch_idx, batch_data in enumerate(train_loader):\n",
    "            x, y = batch_data\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            opt.zero_grad()  \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        outputs = model(x_train)\n",
    "        train_loss = criterion(outputs, y_train) / x_train.shape[0]\n",
    "        predicted = torch.max(outputs, 1)[1]\n",
    "        train_acc = (predicted == y_train).sum() / x_train.shape[0]\n",
    "        \n",
    "        outputs = model(x_test)\n",
    "        vali_loss = criterion(outputs, y_test)  / x_test.shape[0]\n",
    "        predicted = torch.max(outputs, 1)[1]\n",
    "        vali_acc = (predicted == y_test).sum() / x_test.shape[0]\n",
    "        print(f'epoch: {i}, train_loss: {train_loss:.6f}, train_acc: {train_acc:.6f}, vali_loss: {vali_loss:.6f}, vali_acc: {vali_acc:.6f}')\n",
    "        \n",
    "        step = step + 1\n",
    "        #模型性能有所提升则保存模型，并更新loss_value\n",
    "        if vali_acc > acc_value:\n",
    "            step = 0\n",
    "            torch.save(model, model_save_path + f'sub_{sub_idx}.ckpt') \n",
    "            acc_value = vali_acc\n",
    "        \n",
    "        if step >= patient:\n",
    "            break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c2c3e1-6799-4430-912e-a099ac3fb362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"PATH\"] += os.pathsep +'C:/Program Files/Graphviz/bin'\n",
    "# plot_model(model,'cnn2_dens2.jpg', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da196c-428c-4dc0-8b42-841f4fdcc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "第五步：绘图。每20次保留一次loss可以看出大概迭代了120次\n",
    "（20个epoch,每个epoch有118个batch_idx,每20个batch_idx保留一次），\n",
    "从图中可以看出，经历了10次迭代后就逐渐稳定下来了。\n",
    "\"\"\"\n",
    "\n",
    "fig=plt.figure(figsize=(20,15))\n",
    "#x轴斜体避免重叠\n",
    "fig.autofmt_xdate()\n",
    "loss_df=pd.DataFrame(loss_holder,columns=['time','loss'])\n",
    "x_times=loss_df['time'].values\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('times')\n",
    "plt.plot(loss_df['loss'].values)\n",
    "plt.xticks([10,30,50,70,80,100,120,140,160,200])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57881d14-bf37-43c4-9a72-fe11790200f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "model_path='model.ckpt'\n",
    "model=torch.load(model_path)\n",
    "#转化为测试模式\n",
    "model.eval()\n",
    "for layer in model.modules():\n",
    "    layer.requires_grad=False\n",
    "    for batch_idx, (data,label) in enumerate(test_loader):\n",
    "        #只进行前向传播，不进行反向传播\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        print('Test loss{:.6f},Dealed/Records:{}/{}'.format(loss/batch_size,(batch_idx+1)*batch_size,60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09fd3d-4718-4710-bbb0-122519ff7bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 建立模型\n",
    "\n",
    "\n",
    "# callbacksList = [EarlyStopping(monitor = 'val_acc', patience=10, verbose = 1), # patience当连续多少个epochs时验证集精度不再变好终止训练\n",
    "#                 ModelCheckpoint(filepath = f'model/model.h5',monitor='acc',save_best_only=True,)\n",
    "# ]\n",
    "\n",
    "# # 评估\n",
    "# model = load_model('model/model.h5')\n",
    "# score = model.evaluate(x_test, y__v_test, verbose = 1)\n",
    "\n",
    "# \"\"\"\n",
    "# Epoch 39/200\n",
    "# 2160/2160 [==============================] - 59s 27ms/step - loss: 0.0448 - acc: 0.9878 - val_loss: 0.5709 - val_acc: 0.9161\n",
    "# \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
